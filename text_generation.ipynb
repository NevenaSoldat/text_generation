{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation\n",
    "\n",
    "The goal of this project is to demonstrate text generation using LSTM neural networks.\n",
    "Our database contains numerous movie plots taken from Wikipedia, so we will generate something similiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from keras.models import Sequential\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max movie plot len:  36773\n",
      "Min movie plot len:  15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'United States Air Force Colonel William Hughes (Paul Kelly) asks Major Paul Peterson (John Payne), who has been called back to active service, to join a team at the Air Research and Development Command conducting tests on a downward ejection seat for bombardiers in the new Boeing B-47 Stratojet bomber. The first tests used articulated dummies, but human test subjects are needed. Besides Colonel Hughes, German scientist Dr. Franz Gruener (Gregory Gaye), also is in charge of the test program, working directly with the test subjects. Captain Jack Nolan (Richard Crane) is also assigned to the project.\\r\\nThe first volunteer, Captain Mike Cavallero (Eddie Firestone), suffers a broken neck when his parachute opens too early. He survives the test but is hospitalized. The next subject is Lieutenant Edward Simmons, to be followed by Paul. When Mike is suddenly rushed to hospital with an appendicitis attack, Paul moves up. Worried because he has a wife and son, Paul is reluctant to go, but then finds out that Captain Nolan has been killed in a B-47 crash, and as the bombardier, he might not have been able to escape the aircraft.\\r\\nHis wife (Karen Steele) begs his commanding officer to release Paul from his commitment. When Paul shows up to take the test, he finds Colonel Hughes suiting up. Imploring him to reconsider, Paul makes the case for doing the test to prove that a bailout is possible from the high-speed jet bomber. Flying with Dr. Gruener, Paul ejects, but when the ground observers ask him to indicate he is well by spread-eagling, he does not respond. On board the rescue launch, they pick up Paul and find he is fine; he was simply concentrating so hard that he forgot to spread-eagle. After he is cleared by the medics, Paul is greeted by Carol and his son Kit (Richard Eyer) and, with their blessing, decides to continue with the project.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"movie_plots.csv\")\n",
    "\n",
    "movie_plots = data['Plot']\n",
    "print(\"Max movie plot len: \", movie_plots.map(len).max())\n",
    "print(\"Min movie plot len: \", movie_plots.map(len).min())\n",
    "\n",
    "all_plots = list(movie_plots.values)\n",
    "# setting a seed so we get the same result every time\n",
    "random.seed(42)\n",
    "sample = random.sample(all_plots, 100)\n",
    "sample[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize words\n",
    "\n",
    "Tokenization is turning unique words into unique integers. This step is necessary for preparing data for embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   9 3264 3265  815  472    7  104  182  815   75   25 1188    2  969\n",
      "   348 2079    2  530 3266   60  429  815    3 2080  104  116 2081 2082\n",
      "     5 2083 1513    3    4 2084  599  429    3  116 1189  182 3267   44\n",
      "   699    1  473 1190   16    1 1514    5   10  531   10 3268  816    2\n",
      "   182  238   10    3   10 1515  532 3269   53  815 3270 3271   14 1516\n",
      "   116  128   26    1  430 2085   11  182    3  533   10   30   32    1\n",
      "  1513   42    8 3272  211  815   52 2086  429  317  248    2 3273    1\n",
      "    52  970   19    1  348 2080  104  116    3  104    9  600  971  474\n",
      "   117   63   55  161   59    2  212 3274    9  318    2 2087    1 1517\n",
      "  2088  382 2089   79  183    2  601   59 3275  182    2  532    9  318\n",
      "     2 3276    1 3277 2090 1518 1517 2088    9    1  969  348   61  532\n",
      "    63  972    2  162    4 1519   20   38   43 1191    2  142   62    3\n",
      "    63   55  383    2  817    1   52  475   15 1192    7 2091   53 2092\n",
      "    30    7   88  700   42    7 3278  117  971   79  319    3  163   12\n",
      "     8   79  249   12]\n",
      " [1536  388 1537 2130    3  613  286 3348 3349   19   28 3350    9 3351\n",
      "   436   12  546    2    4 3352   22  240  993    4  197 3353   11  165\n",
      "  3354  484 3355 2131    4 2132 2133 3356  101   50  484 1215    2  353\n",
      "   287  547    7   80  107    8   23 2134    1  266 3357  101    9   27\n",
      "  3358  548  834    9 3359   19    1  197    1  614  354   12    8    6\n",
      "  2135    2  138   27  174  130 3360  437 2136 2137   27 3361 1538   15\n",
      "    85    1  614  388    3  613  993    4  835   47  709   19    4 3362\n",
      "  1539 3363  710  613    6 1216    3    1  614    3  388   83   10    2\n",
      "   836   78 2138  254    1 3364    5 2139 3365   47  437 3366  110    1\n",
      "   353  484 3367 3368 2140 3369    1 3370  615 3371  549   10    2 3372\n",
      "  3373   39  388  837   10    2  838  484  982  437    5 2141    1 2139\n",
      "   110    1  353    2    1 3374 1540    9    1  166    5 3375    5 3376\n",
      "  2132  616    8   61  982  437    5  994    7   80 1217   39    8   38\n",
      "     9  548  711   19    9    1  389  484  390  836  438 1541    3  437\n",
      "   354   12  484   23]]\n"
     ]
    }
   ],
   "source": [
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(sample)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sample)\n",
    "sequences_len = 200\n",
    "sequences = pad_sequences(sequences, maxlen = sequences_len, truncating = 'post')\n",
    "sequences.shape\n",
    "print(sequences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size:  20000\n",
      "Vocabulary size:  7003\n"
     ]
    }
   ],
   "source": [
    "# making a single list of tokens so we can apply sliding windows\n",
    "\n",
    "text = [item for sublist in sequences for item in sublist]\n",
    "print(\"Corpus size: \", len(text))\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "print(\"Vocabulary size: \", vocab_size+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse dictionary so we can decode tokenized sequences back to words\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data for input and output values\n",
    "\n",
    "Input sequence has the size of 20 words, and output is the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19980\n"
     ]
    }
   ],
   "source": [
    "seq_len = 20\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(len(text)-seq_len):\n",
    "    seq_in = text[i:i+seq_len]\n",
    "    seq_out = text[i+seq_len]\n",
    "    dataX.append(seq_in)\n",
    "    dataY.append(seq_out)\n",
    "    \n",
    "size = len(dataX)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   9 3264 3265  815  472    7  104  182  815   75   25 1188    2  969\n",
      "  348 2079    2  530 3266   60]\n",
      "429\n",
      "[3264 3265  815  472    7  104  182  815   75   25 1188    2  969  348\n",
      " 2079    2  530 3266   60  429]\n",
      "815\n",
      "in 1931 lon rambeau sends his daughter elizabeth rambeau away from london to napa valley california to visit lon's father\n",
      "philippe\n",
      "1931 lon rambeau sends his daughter elizabeth rambeau away from london to napa valley california to visit lon's father philippe\n",
      "rambeau\n",
      "lon rambeau sends his daughter elizabeth rambeau away from london to napa valley california to visit lon's father philippe rambeau\n",
      "and\n"
     ]
    }
   ],
   "source": [
    "dataX = np.asarray(dataX)\n",
    "dataY = np.asarray(dataY)\n",
    "\n",
    "print(dataX[0])\n",
    "print(dataY[0])\n",
    "print(dataX[1])\n",
    "print(dataY[1])\n",
    "\n",
    "print(\" \".join(map(lambda x : reverse_word_map[x], dataX[0])))\n",
    "print(reverse_word_map[dataY[0]])\n",
    "\n",
    "print(\" \".join(map(lambda x : reverse_word_map[x], dataX[1])))\n",
    "print(reverse_word_map[dataY[1]])\n",
    "\n",
    "print(\" \".join(map(lambda x : reverse_word_map[x], dataX[2])))\n",
    "print(reverse_word_map[dataY[2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19980, 7003)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "trainX = dataX\n",
    "trainy = np_utils.to_categorical(dataY)\n",
    "trainy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 32)            224096    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 20, 100)           53200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7003)              1407603   \n",
      "=================================================================\n",
      "Total params: 1,925,699\n",
      "Trainable params: 1,925,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size+1, 32, input_length = trainX.shape[1]))\n",
    "model.add(LSTM(100,  return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dense(trainy.shape[1], activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nemanja/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 15984 samples, validate on 3996 samples\n",
      "Epoch 1/20\n",
      "15984/15984 [==============================] - 55s 3ms/step - loss: 6.7313 - acc: 0.2048 - val_loss: 6.4812 - val_acc: 0.2060\n",
      "\n",
      "Epoch 00001: loss improved from inf to 6.73129, saving model to ./weights.hdf5\n",
      "Epoch 2/20\n",
      "15984/15984 [==============================] - 59s 4ms/step - loss: 5.9142 - acc: 0.2065 - val_loss: 6.2300 - val_acc: 0.2060\n",
      "\n",
      "Epoch 00002: loss improved from 6.73129 to 5.91423, saving model to ./weights.hdf5\n",
      "Epoch 3/20\n",
      "15984/15984 [==============================] - 70s 4ms/step - loss: 5.5099 - acc: 0.2225 - val_loss: 6.2400 - val_acc: 0.2417\n",
      "\n",
      "Epoch 00003: loss improved from 5.91423 to 5.50988, saving model to ./weights.hdf5\n",
      "Epoch 4/20\n",
      "15984/15984 [==============================] - 74s 5ms/step - loss: 5.3603 - acc: 0.2406 - val_loss: 6.2069 - val_acc: 0.2490\n",
      "\n",
      "Epoch 00004: loss improved from 5.50988 to 5.36026, saving model to ./weights.hdf5\n",
      "Epoch 5/20\n",
      "15984/15984 [==============================] - 77s 5ms/step - loss: 5.2610 - acc: 0.2460 - val_loss: 6.4534 - val_acc: 0.2540\n",
      "\n",
      "Epoch 00005: loss improved from 5.36026 to 5.26100, saving model to ./weights.hdf5\n",
      "Epoch 6/20\n",
      "15984/15984 [==============================] - 75s 5ms/step - loss: 5.1830 - acc: 0.2523 - val_loss: 6.5119 - val_acc: 0.2553\n",
      "\n",
      "Epoch 00006: loss improved from 5.26100 to 5.18305, saving model to ./weights.hdf5\n",
      "Epoch 7/20\n",
      "15984/15984 [==============================] - 73s 5ms/step - loss: 5.1136 - acc: 0.2562 - val_loss: 6.5561 - val_acc: 0.2620\n",
      "\n",
      "Epoch 00007: loss improved from 5.18305 to 5.11358, saving model to ./weights.hdf5\n",
      "Epoch 8/20\n",
      "15984/15984 [==============================] - 79s 5ms/step - loss: 5.0516 - acc: 0.2588 - val_loss: 6.6868 - val_acc: 0.2548\n",
      "\n",
      "Epoch 00008: loss improved from 5.11358 to 5.05162, saving model to ./weights.hdf5\n",
      "Epoch 9/20\n",
      "15984/15984 [==============================] - 99s 6ms/step - loss: 4.9887 - acc: 0.2604 - val_loss: 6.7805 - val_acc: 0.2570\n",
      "\n",
      "Epoch 00009: loss improved from 5.05162 to 4.98871, saving model to ./weights.hdf5\n",
      "Epoch 10/20\n",
      "15984/15984 [==============================] - 91s 6ms/step - loss: 4.9274 - acc: 0.2628 - val_loss: 6.8225 - val_acc: 0.2508\n",
      "\n",
      "Epoch 00010: loss improved from 4.98871 to 4.92737, saving model to ./weights.hdf5\n",
      "Epoch 11/20\n",
      "15984/15984 [==============================] - 94s 6ms/step - loss: 4.8683 - acc: 0.2659 - val_loss: 6.8933 - val_acc: 0.2575\n",
      "\n",
      "Epoch 00011: loss improved from 4.92737 to 4.86830, saving model to ./weights.hdf5\n",
      "Epoch 12/20\n",
      "15984/15984 [==============================] - 106s 7ms/step - loss: 4.8091 - acc: 0.2675 - val_loss: 6.8790 - val_acc: 0.2518\n",
      "\n",
      "Epoch 00012: loss improved from 4.86830 to 4.80908, saving model to ./weights.hdf5\n",
      "Epoch 13/20\n",
      "15984/15984 [==============================] - 101s 6ms/step - loss: 4.7492 - acc: 0.2696 - val_loss: 6.9050 - val_acc: 0.2563\n",
      "\n",
      "Epoch 00013: loss improved from 4.80908 to 4.74922, saving model to ./weights.hdf5\n",
      "Epoch 14/20\n",
      "15984/15984 [==============================] - 99s 6ms/step - loss: 4.6909 - acc: 0.2691 - val_loss: 6.9567 - val_acc: 0.2588\n",
      "\n",
      "Epoch 00014: loss improved from 4.74922 to 4.69091, saving model to ./weights.hdf5\n",
      "Epoch 15/20\n",
      "15984/15984 [==============================] - 103s 6ms/step - loss: 4.6328 - acc: 0.2718 - val_loss: 7.0110 - val_acc: 0.2510\n",
      "\n",
      "Epoch 00015: loss improved from 4.69091 to 4.63281, saving model to ./weights.hdf5\n",
      "Epoch 16/20\n",
      "15984/15984 [==============================] - 113s 7ms/step - loss: 4.5806 - acc: 0.2718 - val_loss: 7.0345 - val_acc: 0.2535\n",
      "\n",
      "Epoch 00016: loss improved from 4.63281 to 4.58055, saving model to ./weights.hdf5\n",
      "Epoch 17/20\n",
      "15984/15984 [==============================] - 105s 7ms/step - loss: 4.5237 - acc: 0.2747 - val_loss: 7.1215 - val_acc: 0.2523\n",
      "\n",
      "Epoch 00017: loss improved from 4.58055 to 4.52367, saving model to ./weights.hdf5\n",
      "Epoch 18/20\n",
      "15984/15984 [==============================] - 112s 7ms/step - loss: 4.4728 - acc: 0.2761 - val_loss: 7.1444 - val_acc: 0.2525\n",
      "\n",
      "Epoch 00018: loss improved from 4.52367 to 4.47279, saving model to ./weights.hdf5\n",
      "Epoch 19/20\n",
      "15984/15984 [==============================] - 104s 7ms/step - loss: 4.4219 - acc: 0.2765 - val_loss: 7.1565 - val_acc: 0.2543\n",
      "\n",
      "Epoch 00019: loss improved from 4.47279 to 4.42192, saving model to ./weights.hdf5\n",
      "Epoch 20/20\n",
      "15984/15984 [==============================] - 117s 7ms/step - loss: 4.3731 - acc: 0.2777 - val_loss: 7.2218 - val_acc: 0.2465\n",
      "\n",
      "Epoch 00020: loss improved from 4.42192 to 4.37312, saving model to ./weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "filepath = \"./weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "hist = model.fit(trainX, trainy, epochs = 20, batch_size = 128, verbose = 1, callbacks = callbacks, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model train loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(trainX, trainy, batch_size = 128)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights from a checkpoint\n",
    "\n",
    "filename = \"weights.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(seed_text, num_words, model, max_seq_len = 20):\n",
    "    for i in range(num_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen = max_seq_len, padding = 'pre')\n",
    "        \n",
    "        predicted = model.predict_classes(token_list, verbose = 0)\n",
    "        output_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "                \n",
    "        seed_text = seed_text + \" \" + output_word\n",
    "        \n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man In Black The Local Village And Old\n"
     ]
    }
   ],
   "source": [
    "print(generate_words(\"man in black\", 5, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
